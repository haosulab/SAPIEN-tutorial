{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The visualization of this notebook depends on usage of SAPIEN's `Viewer`, which is not available on Colab. **You need to run this notebook locally**. Besides this notebook, you can also find the latest SAPIEN tutorial at [SAPIEN's documentation](https://sapien.ucsd.edu/docs/latest/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Planning in SAPIEN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial series, you will learn how to solve motion planning in SAPIEN."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Planning Tutorial 1: Plan a Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn the following:\n",
    "\n",
    "- Plan paths for the agent\n",
    "\n",
    "> Note: This tutorial only talks about the basic usages, and the robot only avoids self-collisions (i.e., collisions between the robot links) in this demo. Please refer to *Motion Planning Tutorial 2: Collision Avoidance* to include the environment model and other advanced usages.\n",
    "\n",
    "<a class=\"RRT\" href=\"../assets/RRT.gif\"><img alt=\"../assets/RRT.gif\" src=\"../assets/RRT.gif\" style=\"width: 33%;\" /></a>\n",
    "*Plan with RRTConnect*\n",
    "<a class=\"screw\" href=\"../assets/screw.gif\"><img alt=\"../assets/screw.gif\" src=\"../assets/screw.gif\" style=\"width: 33%;\" /></a>\n",
    "*Plan with screw motion*\n",
    "\n",
    "As shown in the demo, the robot needs to move the three boxes a bit forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IXA-7qRy4ML"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend using [mplib](https://pypi.org/project/mplib/) for motion planning with SAPIEN. `mplib` is a lightweight python package that includes common functionalities for motion planning. You can use `mplib` to plan a collision-free trajectory for a robot, calculate inverse kinematics, and take point cloud observation as an environment model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIDL-wHKzKQ5"
   },
   "outputs": [],
   "source": [
    "%pip install sapien\n",
    "%pip install mplib\n",
    "\n",
    "import sapien.core as sapien\n",
    "import mplib\n",
    "import numpy as np\n",
    "from sapien.utils import Viewer\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    raise RuntimeError(\"The visualization of this notebook cannot be run on Colab! You need to run it locally with a GPU.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the scene we will be using in this tutorial and load the robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize engine and renderer\n",
    "engine = sapien.Engine()\n",
    "engine.set_log_level('critical')\n",
    "renderer = sapien.SapienRenderer()\n",
    "engine.set_renderer(renderer)\n",
    "\n",
    "# Build scene\n",
    "scene_config = sapien.SceneConfig()\n",
    "scene = engine.create_scene(scene_config)\n",
    "scene.set_timestep(1 / 240.0)\n",
    "scene.add_ground(-0.8)\n",
    "physical_material = scene.create_physical_material(1, 1, 0.0)\n",
    "scene.default_physical_material = physical_material\n",
    "\n",
    "builder = scene.create_actor_builder()\n",
    "builder.add_box_collision(half_size=[0.4, 0.4, 0.025])\n",
    "builder.add_box_visual(half_size=[0.4, 0.4, 0.025])\n",
    "table = builder.build_kinematic(name='table')\n",
    "table.set_pose(sapien.Pose([0.56, 0, - 0.025]))\n",
    "\n",
    "builder = scene.create_actor_builder()\n",
    "builder.add_box_collision(half_size=[0.02, 0.02, 0.06])\n",
    "builder.add_box_visual(half_size=[0.02, 0.02, 0.06], color=[1, 0, 0])\n",
    "red_cube = builder.build(name='red_cube')\n",
    "red_cube.set_pose(sapien.Pose([0.4, 0.3, 0.06]))\n",
    "\n",
    "builder = scene.create_actor_builder()\n",
    "builder.add_box_collision(half_size=[0.02, 0.02, 0.04])\n",
    "builder.add_box_visual(half_size=[0.02, 0.02, 0.04], color=[0, 1, 0])\n",
    "green_cube = builder.build(name='green_cube')\n",
    "green_cube.set_pose(sapien.Pose([0.2, -0.3, 0.04]))\n",
    "\n",
    "builder = scene.create_actor_builder()\n",
    "builder.add_box_collision(half_size=[0.02, 0.02, 0.07])\n",
    "builder.add_box_visual(half_size=[0.02, 0.02, 0.07], color=[0, 0, 1])\n",
    "blue_cube = builder.build(name='blue_cube')\n",
    "blue_cube.set_pose(sapien.Pose([0.6, 0.1, 0.07]))\n",
    "\n",
    "# Set light for visualization\n",
    "scene.set_ambient_light([0.5, 0.5, 0.5])\n",
    "scene.add_directional_light([0, 1, -1], [0.5, 0.5, 0.5], shadow=True)\n",
    "scene.add_point_light([1, 2, 2], [1, 1, 1], shadow=True)\n",
    "scene.add_point_light([1, -2, 2], [1, 1, 1], shadow=True)\n",
    "scene.add_point_light([-1, 0, 1], [1, 1, 1], shadow=True)\n",
    "\n",
    "# Load robot\n",
    "loader = scene.create_urdf_loader()\n",
    "robot = loader.load(\"../assets/panda/panda.urdf\")\n",
    "robot.set_root_pose(sapien.Pose([0, 0, 0], [1, 0, 0, 0]))\n",
    "\n",
    "# Set initial joint positions\n",
    "init_qpos = [0, 0.19634954084936207, 0.0, -2.617993877991494, 0.0, 2.941592653589793, 0.7853981633974483, 0, 0]\n",
    "robot.set_qpos(init_qpos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner Configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `mplib`, we need to set up a planner for the robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_names = [link.get_name() for link in robot.get_links()]\n",
    "joint_names = [joint.get_name() for joint in robot.get_active_joints()]\n",
    "planner = mplib.Planner(\n",
    "    urdf=\"../assets/panda/panda.urdf\",\n",
    "    srdf=\"../assets/panda/panda.srdf\",\n",
    "    user_link_names=link_names,\n",
    "    user_joint_names=joint_names,\n",
    "    move_group=\"panda_hand\",\n",
    "    joint_vel_limits=np.ones(7),\n",
    "    joint_acc_limits=np.ones(7)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The URDF file describes the robot, while the [SRDF](http://docs.ros.org/en/kinetic/api/moveit_tutorials/html/doc/urdf_srdf/urdf_srdf_tutorial.html) file complements the URDF and specifies additional information for motion planning. For example, `mplib` loads the `disable_collisions` pairs in SRDF to ignore collisions between certain pairs of links. SRDF files are generated by `MoveIt Setup Assistant`.\n",
    "- To align the link order and joint order between SAPIEN and `mplib`, we need to provide `user_link_names` and `user_joint_names`. After that, `mplib` can tell which joints the `qpos` vector (from SAPIEN) is referring to. Please note that we only care about the active joints (i.e., revolute and prismatic joints) and ignore the fixed joints.\n",
    "- `move_group` specifies the target link for which we may specify target poses to reach. The end-effector of an agent is typically specified as the `move_group`. After specifying the `move_group`, `mplib` only focuses on those active joints along the path from the root link to the `move_group`, since other joints doesn’t affect the pose of the `move_group`. For example, for our `panda` robot arm (7 DoF), the end-effector is `panda_hand`. Only the first seven active joints affect the pose of `panda_hand`, while the last two finger joints don’t.\n",
    "- For safety, the robot cannot move arbitrarily fast. `joint_vel_limits` and `joint_acc_limits` specify the maximum joint velocity and maximum joint acceleration constraints for the active joints along the path from the root link to the `move_group`. `mplib` takes the constraints into account when solving the time-optimal path parameterization.\n",
    "\n",
    "After setting up the planner, we can use it to solve many motion planning tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan with sampling-based algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mplib` supports state-of-the-art sampling-based motion planning algorithms by leveraging [OMPL](https://github.com/ompl/ompl). You can call `planner.plan()` to plan a path for moving the `move_group` link to a target pose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_pose_with_RRTConnect(pose, viewer): # parameter viewer is for later visualization\n",
    "    result = planner.plan(pose, robot.get_qpos(), time_step=1/250)\n",
    "    if result['status'] != \"Success\":\n",
    "        print(result['status'])\n",
    "        return -1\n",
    "    follow_path(result, viewer) # Function that control the robot to follow the planned path, We will define this later\n",
    "    return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, `planner.plan()` takes two required arguments as input. The first one is the target pose of the `move_group` link. It’s a 7-dim list, where the first three elements describe the position part, and the remaining four elements describe the quaternion (wxyz) for the rotation part. **Note that the pose is relative to the frame of the robot’s root link**. The second argument is the current joint positions of all the active joints (e.g., given by SAPIEN). The `planner.plan()` function first solves the inverse kinematics to get the joint positions for the target pose. It then calls the RRTConnect algorithm to find a path in the joint space. Finally, it parameterizes the path to generate time, velocity, and acceleration information.\n",
    "\n",
    "`planner.plan()` returns a dict which includes:\n",
    "\n",
    "- `status`: a string indicates the status:\n",
    "    - `Success`: planned a path successfully.\n",
    "    - `IK Failed`: failed to solve the inverse kinematics. This may happen when the target pose is not reachable.\n",
    "    - `RRT Failed`: failed to find a valid path in the joint space. This may happen when there is no valid path or the task is too complicated.\n",
    "- `position`: a NumPy array of shape $n \\times m$ describes the joint positions of the waypoints. $n$ is the number of waypoints in the path, and each row describes a waypoint. $m$ is the number of active joints that affect the pose of the `move_group` link. For example, for our panda robot arm, each row includes the positions for the first seven joints.\n",
    "- `duration`: a scalar indicates the duration of the output path. `mplib` returns the optimal duration considering the velocity and acceleration constraints.\n",
    "- `time`: a NumPy array of shape $n$ describes the time step of each waypoint. The first element is equal to 0, and the last one is equal to the `duration`. Argument `time_step` determines the interval of the elements.\n",
    "- `velocity`: a NumPy array of shape $n \\times m$ describing the joint velocities of the waypoints.\n",
    "- `acceleration`: a NumPy array of shape $n \\times m$ describing the joint accelerations of the waypoints.\n",
    "\n",
    "`planner.plan()` also takes other optional arguments with default values:\n",
    "\n",
    "- `time_step = 0.1`: `time_step` specify the time interval between the waypoints. The larger the value, the sparser the output waypoints. In this demo, we align the `time_step` with SAPIEN’s time step.\n",
    "- `rrt_range = 0.1`: the incremental distance in the RRTConnect algorithm. The larger the value, the sparser the sampled waypoints (before time parameterization).\n",
    "- `planning_time=1`: time limit for RRTConnect algorithm, in seconds.\n",
    "- `fix_joint_limits=True`: whether to clip the current joint positions if they are out of the joint limits.\n",
    "- `verbose=False`: whether to display some internal outputs.\n",
    "- `use_point_cloud=False` and `use_attach=False`: related to collision avoidance, will be discussed in *Motion Planning Tutorial 2: Collision Avoidance*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow a path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plan()` outputs a time-parameterized path, and we need to drive the robot to follow the path. If you have already finished *Robotics Tutorial 2: Drive Robot with PID Controller* (which is also recommended before starting this tutorial), you might have been familiar with the process of setting up a controller. Depending on your controller, you may only use the returned position information, or use the velocity and acceleration information as well.\n",
    "\n",
    "In this demo, we use the PhysX internal PD controller. We first need to set the drive properties of the active joints at the very beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_joints = robot.get_active_joints()\n",
    "for joint in active_joints:\n",
    "    joint.set_drive_property(stiffness=1000, damping=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To follow a path, at each time step, we set the target position and target velocity according to the returned path. Please note that since we aligned the time step of the returned path with the SAPIEN time step, we don’t need to interpolate the returned path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def follow_path(result, viewer): # parameter viewer is for later visualization\n",
    "    n_step = result['position'].shape[0]\n",
    "    for i in range(n_step):  \n",
    "        qf = robot.compute_passive_force(\n",
    "            gravity=True, \n",
    "            coriolis_and_centrifugal=True)\n",
    "        robot.set_qf(qf)\n",
    "        for j in range(7):\n",
    "            active_joints[j].set_drive_target(result['position'][i][j])\n",
    "            active_joints[j].set_drive_velocity_target(result['velocity'][i][j])\n",
    "        scene.step()\n",
    "        if i % 4 == 0:\n",
    "            scene.update_render()\n",
    "            viewer.render()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compensate the passive forces through `set_qf()` (see *Robotics Tutorial 1: Getting Started with Robot* for details).\n",
    "\n",
    "You can also use your own controller.\n",
    "\n",
    "> Note: If you find your robot doesn’t move as expected, please double-check your controller, especially the controller’s parameters. In many cases, the planner finds a good path while the controller fails to follow the path."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan with screw motion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides using the sampling-based algorithms, we also provide another simple way (trick) to plan a path. For some tasks, we can directly move the `move_group` link towards the target pose. It’s internally achieved by first calculating the relative transformation from its current pose to the target pose, then calculating the relative transformation’s exponential coordinates, and finally calculating the joint velocities with the Jacobian matrix.\n",
    "\n",
    "Compared to the sampling-based algorithms, planning with screw motion has the following pros:\n",
    "\n",
    "faster: since it doesn’t need to sample lots of states in the joint space, planning with screw motion can save lots of planning time.\n",
    "\n",
    "straighter path: there is no guarantee for sampling-based algorithms to generate straight paths even it’s a simple lifting task since it connects states in the joint space. In contrast, the returned path by the exponential coordinates and the Jacobian matrix can sometimes be more reasonable. See the above figures for comparison.\n",
    "\n",
    "You can call `planner.plan_screw()` to plan a path with screw motion. Similar to `planner.plan()`, it also takes two required arguments: target pose and current joint positions, and returns a dict containing the same set of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_pose_with_screw(pose, viewer): # parameter viewer is for later visualization\n",
    "    result = planner.plan_screw(pose, robot.get_qpos(), time_step=1/250)\n",
    "    if result['status'] != \"Success\":\n",
    "        result = planner.plan(pose, robot.get_qpos(), time_step=1/250)\n",
    "        if result['status'] != \"Success\":\n",
    "            print(result['status'])\n",
    "            return -1 \n",
    "    follow_path(result, viewer)\n",
    "    return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, planning with screw motion only succeeds when there is no collision during the planning since it can not detour or replan. We thus recommend use `planner.plan_screw()` for some simple tasks or combined with `planner.plan()`. As shown in the code, we first try `planner.plan_screw()`, if it fails (e.g., collision during the planning), we then turn to the sampling-based algorithms. Other arguments are the same with `planner.plan()`.\n",
    "\n",
    "`planner.plan_screw()` also takes `qpos_step = 0.1`, `time_step = 0.1`, `use_point_cloud = False`, `use_attach = False`, and `verbose = False` as optional arguments, where `qpos_step` specifies the incremental distance of the joint positions during the path generation (before time paramtertization)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the boxes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To control the gripper, we use set_drive_target() to set target positions for the two gripper joints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_gripper(viewer): # parameter viewer is for later visualization\n",
    "    for joint in active_joints[-2:]:\n",
    "        joint.set_drive_target(0.4)\n",
    "    for i in range(100): \n",
    "        qf = robot.compute_passive_force(\n",
    "            gravity=True, \n",
    "            coriolis_and_centrifugal=True)\n",
    "        robot.set_qf(qf)\n",
    "        scene.step()\n",
    "        if i % 4 == 0:\n",
    "            scene.update_render()\n",
    "            viewer.render()\n",
    "\n",
    "def close_gripper(viewer): # parameter viewer is for later visualization\n",
    "    for joint in active_joints[-2:]:\n",
    "        joint.set_drive_target(0)\n",
    "    for i in range(100):  \n",
    "        qf = robot.compute_passive_force(\n",
    "            gravity=True, \n",
    "            coriolis_and_centrifugal=True)\n",
    "        robot.set_qf(qf)\n",
    "        scene.step()\n",
    "        if i % 4 == 0:\n",
    "            scene.update_render()\n",
    "            viewer.render()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we manually mark some landmark poses to move the boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_pose(pose, with_screw, viewer): # parameter viewer is for later visualization\n",
    "    if with_screw:\n",
    "        return move_to_pose_with_screw(pose, viewer)\n",
    "    else:\n",
    "        return move_to_pose_with_RRTConnect(pose, viewer)\n",
    "\n",
    "def demo(with_screw, viewer):\n",
    "    poses = [[0.4, 0.3, 0.12, 0, 1, 0, 0],\n",
    "            [0.2, -0.3, 0.08, 0, 1, 0, 0],\n",
    "            [0.6, 0.1, 0.14, 0, 1, 0, 0]]\n",
    "    for i in range(3):\n",
    "        pose = poses[i]\n",
    "        pose[2] += 0.2\n",
    "        move_to_pose(pose, with_screw, viewer)\n",
    "        open_gripper(viewer)\n",
    "        pose[2] -= 0.12\n",
    "        move_to_pose(pose, with_screw, viewer)\n",
    "        close_gripper(viewer)\n",
    "        pose[2] += 0.12\n",
    "        move_to_pose(pose, with_screw, viewer)\n",
    "        pose[0] += 0.1\n",
    "        move_to_pose(pose, with_screw, viewer)\n",
    "        pose[2] -= 0.12\n",
    "        move_to_pose(pose, with_screw, viewer)\n",
    "        open_gripper(viewer)\n",
    "        pose[2] += 0.12\n",
    "        move_to_pose(pose, with_screw, viewer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to visualize the simulation! You can try to run the simulation loop with/without screw motion planning by specifying `with_screw` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = Viewer(renderer)\n",
    "viewer.set_scene(scene)\n",
    "viewer.set_camera_xyz(x=1.2, y=0.25, z=0.4)\n",
    "viewer.set_camera_rpy(r=0, p=-0.4, y=2.7)\n",
    "\n",
    "demo(with_screw=True, viewer=viewer)\n",
    "\n",
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Reading: Inverse Kinematics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse kinematics determine the joint positions that provide the desired pose for the robot’s end-effectors. In mplib, you can solve the inverse kinematics of the `move_group` link with:\n",
    "\n",
    "    planner.IK(target_pose, init_qpos, n_init_qpos = 20, threshold = 1e-3)\n",
    "\n",
    "`Planner.IK()` internally implements a numerical method and takes the following arguments:\n",
    "\n",
    "- `target_pose`: a 7-dim list specifies the target pose of the `move_group` link. The first three elements describe the position part, and the remaining four elements describe the quaternion (wxyz) for the rotation part.\n",
    "- `init_qpos`: a list describes the joint positions of all the active joints (e.g., given by SAPIEN). It will be used as the initial state for the numerical method.\n",
    "- `n_init_qpos=20`: besides the provided initial state, the method also samples extra initial states to run the algorithm for at most `n_init_qpos` times. In this way, it can avoid local minimums and increase the success rate.\n",
    "- `threshold=1e-3`: a threshold for determining whether the calculated pose is close enough to to the target pose.\n",
    "\n",
    "It returns a tuple of two elements:\n",
    "- `status`: a string indicates the status.\n",
    "- `result`: a NumPy array describes the calculated joint positions.\n",
    "\n",
    "If `planner.IK()` fails, please increase `n_init_qpos` or double-check whether the target pose is reachable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sapien",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52cc33f0f2a37b136af3b056cd1b16fcde515625a8da3d7221199fda542f2c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
